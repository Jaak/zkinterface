\section{Description}
		
		zkInterface is a purely functional interface for zero-knowledge systems that enables cross-language interoperability via dynamic linking and shared memory. The current version, even if limiting, creates an interface based on R1CS formatting and offers the ability to abstractly craft a constraint system building from different components, possibly written in different frameworks, by determining how data should be written and read. 
		
		It can also be seen as a design tool for improved generation of constraints and usability, analogous to a portable binary format, since one can parametrize the functions calls and easily compose different functions, or components, that are not directly compatible.
		
		It is important to point out that the interface can be called both to write a request or read a response by having an encoder at the front-end  and a decoder at the back-end. 
		
		\paragraph{Main functionality.}
		
		The interface works across every zero-knowledge front-end and back-end, minimizing, when possible, the overhead of using a general format. This is achieved in several ways:
        
        \begin{itemize}
			\item By using a protoboard-like method for shared memory allocation, and thus preventing double-copying the data unnecessarily.
			\item By parametrizing the function calls to the different components so to take advantage of the specific context underlying those components.
			\item By using FlatBuffers, an efficient cross platform serialization library for different languages. This tool allows us to easily write ad-hoc parsers from scratch and has a very low overhead in shared memory, which can be used in regular function calls. 
		\end{itemize}
		
		
        
        The two main purposes of the interface are the computations of the \emph{instance reduction}, which generates a portable circuit or constraint system, and the \emph{witness reduction}, which assigns values to the variables allocated in the instance reduction. We have designed the interface so that each of these two processes actually use the same exact routine, except with different message types.

        Essentially, as seen in Figure \ref{flow}, the caller of the interface can be both an application or a component that requires a sub-component, an abstraction that helps make the interface minimal. Say I want to compute a proof of set membership by using a Merkle Tree of hashes. Then, the flow is the following:
        \begin{enumerate} 
            \item The application will call the Merkle Tree component that exists in some front-end framework, which starts allocating in memory the variables and constraints in the standard R1CS format.
            \item For every hash computation needed to generate the path, the Merkle Tree will itself call a hasher sub-component, possibly from a different framework, by passing it the parameters, including the next free memory slot for allocating the hash constraints and variables.
            \item The hash component will then allocate in memory the constraints and variables, to which the Merkle Tree component is oblivious (except the shared input / outputs: the input message and the output hash digest).
            \item Specifically, for each call to the hash component, the input message is given as part of the request and the hash component sends the hash digest as part of the response. The rest of the variables are locally dealt with by the hash component but are shared in memory by all the components.
        \end{enumerate}
        
        Note how the routine can be re-used by the witness reduction and deterministically assign the values to the respective variables in memory. Moreover, if needed, the constraint system can be outputed as a file containing a static rank-1 constraint system. One objection to using this routine design is that the component at the top level (i.e.: the Merkle Tree) cannot is waiting for the response of the sub-component (i.e.: the hasher component). This can have a cost in the efficiency of the circuit generation if we imagine a long enough chain of sub-calls that would cause a quadratic overhead. This is unlikely to happen in the current set of applications and circuits. \dtodo{Please check that this is true}
		
			\begin{figure}[h!]
				\includegraphics[width=\linewidth]{routine.png}
				\caption{The flow of interaction between existing libraries and the interface}
				\label{flow}
			\end{figure}

		\paragraph{Instance reduction.} 
		
        Points to include:
        - caller does not provide functionality to gadget and does not depend on specific implementation
        - gadget and caller both allocate variables
		
		\paragraph{Witness reduction.}
		
		r1cs in the format: a way to represent the constraints and a way to represent the assignment; and connection between components (gadgets), which actually are the public inputs. If we think of circuit as components, each component has a set of local inputs and "outgoing" inputs.
		
		So the interface solves two problems: 1/ interop between frameworks (front-ends) and proving systems (backends) 2/ composability of gadgets between different frameworks.
		
	
		
		\subsection{An MVP}
		
        \paragraph{Standard Format.}

		*use of flatboard
		
		- semantics; planned parametrization of the semantics.
		
		- format: can work with files (all messages instead of processing, can be written to file) for both instance / witness reduction, otherwise can work with memory 
		
		Each component has an interface; which can be invoked / instantiated / called with other components to make up the constraint system.
			- composibility of gadgets as there local variables / public ones (merkle tree has the leaf and root and invokes sha256)
		
		CRS is specific to proving system so the format does not handle the CRS portability
		
		we are thinking of implementing ZoKrates for the application layer and libsnark, bellman.  
		
		NOTE: some people think of functions, inputs and returned variables; others as circuits and gadgets.
		
		
		Issues: 1/ linear 